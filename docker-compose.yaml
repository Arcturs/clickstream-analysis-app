x-airflow-common:
  &airflow-common
  # In order to add custom dependencies or upgrade provider distributions you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the "build" line below, Then run `docker-compose build` to build the images.
  build:
    context: airflow/
    dockerfile: Dockerfile
  # build: .
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
    AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: 10
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/config:/opt/airflow/config
    - ./airflow/plugins:/opt/airflow/plugins
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy
    cassandra-seed-dwh-clean:
      condition: service_healthy
    cassandra-node2-dwh-clean:
      condition: service_healthy
    clickhouse-01:
      condition: service_healthy
    clickhouse-02:
      condition: service_healthy

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
    ports:
      - "2181:2181"

  kafka1:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:9092,EXTERNAL://host.docker.internal:9092
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    depends_on:
      - zookeeper

  kafka2:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:9092,EXTERNAL://host.docker.internal:9094
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    depends_on:
      - zookeeper

  init-topic-1:
    image: confluentinc/cp-kafka:7.6.1
    command: >
      bash -c "
      echo 'Waiting for Kafka to be ready...';
      cub kafka-ready -b kafka1:9092,kafka2:9094 1 60 &&
      kafka-topics --create --if-not-exists --bootstrap-server kafka1:9092,kafka2:9094 --topic app.messages --partitions 4 --replication-factor 2 --config retention.ms=604800000
      "
    depends_on:
      - kafka1
      - kafka2

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "7777:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: kafka-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092,kafka2:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - kafka1
      - kafka2
      - init-topic-1

  generator:
    image: generator
    container_name: generator
    build:
      context: generator/
    ports:
      - "8081:8080"
      - "8092:8091"
    depends_on:
      - zookeeper
      - kafka1
      - kafka2
    environment:
      KAFKA_BOOTSTRAP_SERVER: host.docker.internal:9092,host.docker.internal:9094

  cassandra-seed-dwh:
    image: cassandra:4.1
    container_name: cassandra-seed-dwh
    hostname: cassandra-seed-dwh
    environment:
      CASSANDRA_CLUSTER_NAME: MyCluster
      CASSANDRA_SEEDS: cassandra-seed-dwh,cassandra-node-dwh
      CASSANDRA_DC: datacenter1
      CASSANDRA_RACK: rack1
      CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
    volumes:
      - cassandra-seed-data-dwh:/var/lib/cassandra
      - ./init-scripts/cassandra-dwh:/docker-entrypoint-initdb.d:ro
    ports:
      - "9042:9042"
    networks:
      - cassandra-network-dwh
    healthcheck:
      test: [ "CMD", "cqlsh", "-e", "describe keyspaces" ]
      interval: 30s
      timeout: 10s
      retries: 10

  cassandra-node2-dwh:
    image: cassandra:4.1
    container_name: cassandra-node2-dwh
    hostname: cassandra-node2-dwh
    depends_on:
      cassandra-seed-dwh:
        condition: service_healthy
    environment:
      CASSANDRA_CLUSTER_NAME: MyCluster
      CASSANDRA_SEEDS: cassandra-seed-dwh,cassandra-node2-dwh
      CASSANDRA_DC: datacenter1
      CASSANDRA_RACK: rack1
      CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
    volumes:
      - cassandra-node2-data-dwh:/var/lib/cassandra
    networks:
      - cassandra-network-dwh

  api:
    image: api
    container_name: api
    build:
      context: api/
    ports:
      - "8080:8080"
      - "8091:8091"
    depends_on:
      - cassandra-node2-dwh
      - cassandra-seed-dwh
    environment:
      CASSANDRA_HOST: host.docker.internal

  minio:
    image: minio/minio:RELEASE.2025-07-23T15-54-02Z
    container_name: minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001" # Web UI порт
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_DOMAIN: localhost
    volumes:
      - minio_data:/data

  mc:
    image: minio/mc:RELEASE.2025-07-21T05-28-08Z
    container_name: mc
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      mc alias set local http://minio:9000 minioadmin minioadmin;
      mc mb local/click-analysis --ignore-existing;
      mc policy set public local/click-analysis;
      tail -f /dev/null
      "
    depends_on:
      - minio

  minio-to-cassandra:
    image: minio-to-cassandra
    container_name: minio-to-cassandra
    build:
      context: flink-jobs/
    ports:
      - "8082:8080"
      - "8093:8091"
    depends_on:
      - cassandra-node2-dwh
      - cassandra-seed-dwh
      - minio
      - mc
    environment:
      ACTIVE_PROFILE: minio-to-cassandra
      CASSANDRA_HOST: host.docker.internal

  kafka-to-cassandra:
    image: kafka-to-cassandra
    container_name: kafka-to-cassandra
    build:
      context: flink-jobs/
    ports:
      - "8083:8080"
      - "8094:8091"
    depends_on:
      - cassandra-node2-dwh
      - cassandra-seed-dwh
      - kafka1
      - kafka2
      - init-topic-1
    environment:
      ACTIVE_PROFILE: minio-to-cassandra
      CASSANDRA_HOST: host.docker.internal
      KAFKA_BOOTSTRAP_SERVER: host.docker.internal:9092,host.docker.internal:9094

  cassandra-seed-dwh-clean:
    image: cassandra:4.1
    container_name: cassandra-seed-dwh-clean
    hostname: cassandra-seed-dwh-clean
    environment:
      CASSANDRA_CLUSTER_NAME: MyCluster
      CASSANDRA_SEEDS: cassandra-seed-dwh-clean,cassandra-node2-dwh-clean
      CASSANDRA_DC: datacenter1
      CASSANDRA_RACK: rack1
      CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
    volumes:
      - cassandra-seed-data-clean:/var/lib/cassandra
      - ./init-scripts/cassandra-dwh-clean:/docker-entrypoint-initdb.d:ro
    ports:
      - "9043:9042"
    networks:
      - cassandra-network-dwh-clean
    healthcheck:
      test: [ "CMD", "cqlsh", "-e", "describe keyspaces" ]
      interval: 30s
      timeout: 10s
      retries: 10

  cassandra-node2-dwh-clean:
    image: cassandra:4.1
    container_name: cassandra-node2-dwh-clean
    hostname: cassandra-node2-dwh-clean
    depends_on:
      cassandra-seed-dwh-clean:
        condition: service_healthy
    environment:
      CASSANDRA_CLUSTER_NAME: MyCluster
      CASSANDRA_SEEDS: cassandra-seed-dwh-clean,cassandra-node2-dwh-clean
      CASSANDRA_DC: datacenter1
      CASSANDRA_RACK: rack1
      CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
    volumes:
      - cassandra-node2-data-clean:/var/lib/cassandra
    networks:
      - cassandra-network-dwh-clean

  cassandra-to-cassandra:
    image: cassandra-to-cassandra
    container_name: cassandra-to-cassandra
    build:
      context: flink-jobs/
    ports:
      - "8084:8080"
      - "8095:8091"
    depends_on:
      - cassandra-node2-dwh
      - cassandra-seed-dwh
      - cassandra-node2-dwh-clean
      - cassandra-seed-dwh-clean
    environment:
      ACTIVE_PROFILE: cassandra-to-cassandra
      CASSANDRA_HOST: host.docker.internal

  clickhouse-zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    container_name: clickhouse-zookeeper
    ports:
      - "2182:2181"
    environment:
      ZOO_MY_ID: 2
      ZOO_SERVERS: zookeeper:2888:3888
    networks:
      - clickhouse-net

  clickhouse-01:
    image: clickhouse/clickhouse-server:24.3
    container_name: clickhouse-01
    hostname: clickhouse-01
    ports:
      - "8123:8123"  # HTTP
      - "9000:9000"  # Native protocol
      - "9009:9009"  # Interserver HTTP
    volumes:
      - ./clickhouse/configs/clickhouse-01:/etc/clickhouse-server
      - clickhouse-01-data:/var/lib/clickhouse
      - ./clickhouse/logs/clickhouse-01:/var/log/clickhouse-server
      - ./init-scripts/clickhouse/:/docker-entrypoint-initdb.d:ro
    environment:
      CLICKHOUSE_DB: analytics
      CLICKHOUSE_USER: admin
      CLICKHOUSE_PASSWORD: admin
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    depends_on:
      - clickhouse-zookeeper
    networks:
      - clickhouse-net

  clickhouse-02:
    image: clickhouse/clickhouse-server:24.3
    container_name: clickhouse-02
    hostname: clickhouse-02
    ports:
      - "8124:8123"
      - "9001:9000"
      - "9010:9009"
    volumes:
      - ./clickhouse/configs/clickhouse-02:/etc/clickhouse-server
      - clickhouse-02-data:/var/lib/clickhouse
      - ./clickhouse/logs/clickhouse-02:/var/log/clickhouse-server
    environment:
      CLICKHOUSE_DB: analytics
      CLICKHOUSE_USER: admin
      CLICKHOUSE_PASSWORD: admin
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    depends_on:
      - clickhouse-zookeeper
    networks:
      - clickhouse-net

  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "airflow" ]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  airflow-apiserver:
    <<: *airflow-common
    command: api-server
    ports:
      - "8090:8080"
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8090/api/v2/monitor/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8974/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    <<: *airflow-common
    command: version
    environment:
      <<: *airflow-common-env
      AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: airflow
      _AIRFLOW_WWW_USER_PASSWORD: airflow
    user: "0:0"

  prometheus:
    image: prom/prometheus:v3.2.0
    container_name: prometheus
    user: "$UID:$GID"
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/:/etc/prometheus/
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yaml'
      - '--storage.tsdb.path=/'

  grafana:
    image: grafana/grafana:11.6.0
    ports:
      - "3001:3001"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SERVER_HTTP_PORT=3001
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_SERVER_DOMAIN=localhost
    depends_on:
      - prometheus

volumes:
  cassandra-seed-data-dwh:
  cassandra-node2-data-dwh:
  minio_data:
  cassandra-seed-data-clean:
  cassandra-node2-data-clean:
  clickhouse-01-data:
  clickhouse-02-data:
  postgres-db-volume:
  prometheus-data:
  grafana-data:

networks:
  cassandra-network-dwh:
    driver: bridge
  cassandra-network-dwh-clean:
    driver: bridge
  clickhouse-net:
    driver: bridge
